apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: src-file-system-file-pulse
  labels:
    # The strimzi.io/cluster label identifies the KafkaConnect instance
    # in which to create this connector. That KafkaConnect instance
    # must have the strimzi.io/use-connector-resources annotation
    # set to true.
    strimzi.io/cluster: kafka-connect
spec:
  class: io.streamthoughts.kafka.connect.filepulse.source.FilePulseSourceConnector
  tasksMax: 1
  config:
    topic: "acidentes_antt"
    fs.listing.class: "io.streamthoughts.kafka.connect.filepulse.fs.LocalFSDirectoryListing"
    fs.listing.directory.path: "/opt/data/"
    fs.listing.filters: "io.streamthoughts.kafka.connect.filepulse.fs.filter.RegexFileListFilter"
    file.filter.regex.pattern: ".*\\.csv$"
    fs.listing.interval.ms: "300000"
    offset.policy.class: "io.streamthoughts.kafka.connect.filepulse.offset.DefaultSourceOffsetPolicy"
    offset.attributes.string: "name"
    skip.headers: "1"
    tasks.reader.class: "io.streamthoughts.kafka.connect.filepulse.fs.reader.LocalRowFileInputReader"
    fs.cleanup.policy.class: "io.streamthoughts.kafka.connect.filepulse.fs.clean.LogCleanupPolicy"
    tasks.file.status.storage.class: "io.streamthoughts.kafka.connect.filepulse.state.KafkaFileObjectStateBackingStore"
    tasks.file.status.storage.bootstrap.servers: "http://kafka-cluster-kafka-bootstrap:9092"
    tasks.file.status.storage.topic: "connect-file-pulse-status"
    tasks.file.status.storage.topic.partitions: 5
    tasks.file.status.storage.topic.replication.factor: 1
    key.converter: "io.confluent.connect.avro.AvroConverter"
    key.converter.schema.registry.url: "http://schema-registry:8081"
    value.converter: "io.confluent.connect.avro.AvroConverter"
    value.converter.schema.registry.url: "http://schema-registry:8081"
    filters: "ParseCSVLine"
    filters.ParseCSVLine.type: "io.streamthoughts.kafka.connect.filepulse.filter.CSVFilter"
    filters.ParseCSVLine.extract.column.name: "headers"
    filters.ParseCSVLine.separator: ","
    filters.ParseCSVLine.trim.column: "true"